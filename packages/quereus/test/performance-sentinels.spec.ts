/**
 * Performance sentinel tests.
 *
 * These are NOT micro-benchmarks; they are regression sentinels that assert
 * "this workload completes in well under N ms on CI-class hardware".
 * Thresholds are intentionally generous (10–50× headroom) so they only trip
 * when something regresses catastrophically.
 *
 * Run: yarn test --grep "Performance sentinels"
 */

import { expect } from 'chai';
import { Database } from '../src/index.js';
import { Parser } from '../src/parser/parser.js';

/** Collect an async iterable into an array. */
async function collect<T>(iter: AsyncIterable<T>): Promise<T[]> {
	const out: T[] = [];
	for await (const item of iter) out.push(item);
	return out;
}

/** Time an async function in milliseconds. */
async function timeMs(fn: () => Promise<void>): Promise<number> {
	const start = performance.now();
	await fn();
	return performance.now() - start;
}

describe('Performance sentinels', function () {
	// Allow generous timeouts for CI
	this.timeout(30_000);

	// ------------------------------------------------------------------ Parser
	describe('Parser', () => {
		it('parses a simple SELECT under 5 ms', () => {
			const sql = 'select id, name, email from users where active = 1 order by name';
			const parser = new Parser();
			const start = performance.now();
			for (let i = 0; i < 100; i++) {
				parser.parseAll(sql);
			}
			const elapsed = performance.now() - start;
			// 100 parses should be well under 500 ms even on slow hardware
			expect(elapsed).to.be.below(500, `100 simple parses took ${elapsed.toFixed(1)} ms`);
		});

		it('parses a wide SELECT (50 columns) under 10 ms', () => {
			const cols = Array.from({ length: 50 }, (_, i) => `col_${i}`).join(', ');
			const sql = `select ${cols} from big_table where col_0 > 10`;
			const parser = new Parser();
			const start = performance.now();
			for (let i = 0; i < 100; i++) {
				parser.parseAll(sql);
			}
			const elapsed = performance.now() - start;
			expect(elapsed).to.be.below(1000, `100 wide-SELECT parses took ${elapsed.toFixed(1)} ms`);
		});

		it('parses a deeply nested expression under 20 ms', () => {
			// Build: ((((1 + 2) + 3) + 4) ... + 30)
			let expr = '1';
			for (let i = 2; i <= 30; i++) expr = `(${expr} + ${i})`;
			const sql = `select ${expr} as result`;
			const parser = new Parser();
			const start = performance.now();
			for (let i = 0; i < 100; i++) {
				parser.parseAll(sql);
			}
			const elapsed = performance.now() - start;
			expect(elapsed).to.be.below(1500, `100 nested-expression parses took ${elapsed.toFixed(1)} ms`);
		});
	});

	// --------------------------------------------------------- End-to-end query
	describe('End-to-end query execution', () => {
		let db: Database;

		beforeEach(async () => {
			db = new Database();
			// Create a table with 1000 rows
			await db.exec('create table perf_t (id integer primary key, val integer, label text)');
			const batches: string[] = [];
			for (let i = 0; i < 10; i++) {
				const values = Array.from({ length: 100 }, (_, j) => {
					const id = i * 100 + j + 1;
					return `(${id}, ${id * 7 % 100}, 'label_${id % 20}')`;
				}).join(', ');
				batches.push(`insert into perf_t values ${values}`);
			}
			for (const batch of batches) {
				await batch; // force sequential
				await db.exec(batch);
			}
		});

		afterEach(async () => {
			await db.close();
		});

		it('full table scan (1000 rows) under 200 ms', async () => {
			const elapsed = await timeMs(async () => {
				const rows = await collect(db.eval('select * from perf_t'));
				expect(rows).to.have.length(1000);
			});
			expect(elapsed).to.be.below(200, `scan took ${elapsed.toFixed(1)} ms`);
		});

		it('filtered scan (1000 rows, ~10 matches) under 200 ms', async () => {
			const elapsed = await timeMs(async () => {
				const rows = await collect(db.eval('select * from perf_t where val = 42'));
				expect(rows.length).to.be.greaterThan(0);
			});
			expect(elapsed).to.be.below(200, `filtered scan took ${elapsed.toFixed(1)} ms`);
		});

		it('aggregate GROUP BY under 200 ms', async () => {
			const elapsed = await timeMs(async () => {
				const rows = await collect(
					db.eval('select label, count(*) as cnt, sum(val) as total from perf_t group by label')
				);
				expect(rows.length).to.be.greaterThan(0);
			});
			expect(elapsed).to.be.below(200, `group by took ${elapsed.toFixed(1)} ms`);
		});

		it('ORDER BY under 200 ms', async () => {
			const elapsed = await timeMs(async () => {
				const rows = await collect(
					db.eval('select * from perf_t order by val desc, id asc')
				);
				expect(rows).to.have.length(1000);
			});
			expect(elapsed).to.be.below(200, `order by took ${elapsed.toFixed(1)} ms`);
		});

		it('self-join under 8 s (nested-loop baseline)', async () => {
			// NOTE: this is slow due to nested-loop join — hash join would bring
			// this down to ~100 ms.  The generous threshold exists to catch
			// catastrophic regressions; see tasks/plan/4-join-algorithms.md.
			const elapsed = await timeMs(async () => {
				const rows = await collect(
					db.eval(`
						select a.id, b.id as b_id
						from perf_t a join perf_t b on a.val = b.val
						where a.id <= 50
					`)
				);
				expect(rows.length).to.be.greaterThan(0);
			});
			expect(elapsed).to.be.below(8000, `self-join took ${elapsed.toFixed(1)} ms`);
		});

		it('correlated subquery under 500 ms', async () => {
			const elapsed = await timeMs(async () => {
				const rows = await collect(
					db.eval(`
						select id, val,
							(select count(*) from perf_t b where b.val = a.val) as peer_count
						from perf_t a
						where a.id <= 50
					`)
				);
				expect(rows).to.have.length(50);
			});
			expect(elapsed).to.be.below(500, `correlated subquery took ${elapsed.toFixed(1)} ms`);
		});
	});

	// --------------------------------------------------------- Bulk mutations
	describe('Bulk mutations', () => {
		let db: Database;

		beforeEach(() => {
			db = new Database();
		});

		afterEach(async () => {
			await db.close();
		});

		it('bulk insert 1000 rows under 500 ms', async () => {
			await db.exec('create table bulk_t (id integer primary key, val integer)');

			const elapsed = await timeMs(async () => {
				for (let i = 0; i < 10; i++) {
					const values = Array.from({ length: 100 }, (_, j) => {
						const id = i * 100 + j + 1;
						return `(${id}, ${id * 3})`;
					}).join(', ');
					await db.exec(`insert into bulk_t values ${values}`);
				}
			});
			expect(elapsed).to.be.below(500, `bulk insert took ${elapsed.toFixed(1)} ms`);

			// Verify
			const rows = await collect(db.eval('select count(*) as cnt from bulk_t'));
			expect(rows[0].cnt).to.equal(1000);
		});

		it('index lookup after bulk insert under 100 ms', async () => {
			await db.exec(`
				create table idx_t (id integer primary key, category integer, name text);
				create index idx_t_category on idx_t (category);
			`);

			// Insert 500 rows
			const values = Array.from({ length: 500 }, (_, i) =>
				`(${i + 1}, ${i % 10}, 'name_${i}')`
			).join(', ');
			await db.exec(`insert into idx_t values ${values}`);

			const elapsed = await timeMs(async () => {
				// 50 point lookups by primary key
				for (let i = 1; i <= 50; i++) {
					const row = await db.get(`select * from idx_t where id = ?`, [i]);
					expect(row).to.exist;
				}
			});
			expect(elapsed).to.be.below(500, `50 PK lookups took ${elapsed.toFixed(1)} ms`);
		});
	});

	// ------------------------------------------------- Repeated prepare/execute
	describe('Statement reuse', () => {
		let db: Database;

		beforeEach(async () => {
			db = new Database();
			await db.exec('create table reuse_t (id integer primary key, v integer)');
			const values = Array.from({ length: 100 }, (_, i) => `(${i + 1}, ${i * 2})`).join(', ');
			await db.exec(`insert into reuse_t values ${values}`);
		});

		afterEach(async () => {
			await db.close();
		});

		it('50 prepare+execute cycles under 500 ms', async () => {
			const elapsed = await timeMs(async () => {
				for (let i = 1; i <= 50; i++) {
					const rows = await collect(db.eval('select * from reuse_t where id = ?', [i]));
					expect(rows).to.have.length(1);
				}
			});
			expect(elapsed).to.be.below(500, `50 prepare+execute cycles took ${elapsed.toFixed(1)} ms`);
		});
	});
});

